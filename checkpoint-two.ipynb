{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "151601c9-ca7a-412e-af80-c62a87e0837e"
            },
            "source": [
                "# Checkpoint Two: Exploratory Data Analysis\n",
                "\n",
                "Now that your chosen dataset is approved, it is time to start working on your analysis. Use this notebook to perform your EDA and make notes where directed to as you work.\n",
                "\n",
                "## Getting Started\n",
                "\n",
                "Since we have not provided your dataset for you, you will need to load the necessary files in this repository. Make sure to include a link back to the original dataset here as well.\n",
                "\n",
                "My dataset: https://catalog.data.gov/dataset/alzheimers-disease-and-healthy-aging-data\n",
                "\n",
                "Your first task in EDA is to import necessary libraries and create a dataframe(s). Make note in the form of code comments of what your thought process is as you work on this setup task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "7b503e37-6df5-4433-acfb-678b1346db14"
            },
            "outputs": [],
            "source": [
                "# Pre-filtered the overall excel file down to the two questions I want to analyze from the survey data.\n",
                "# So the file I'm importing is already a filtered dataset from the main dataset.\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "\n",
                "df = pd.read_csv(\"./filtered-dataset.csv\")\n",
                "\n",
                "# Looks like 0 duplicated rows\n",
                "df.duplicated().sum()\n",
                "\n",
                "df.columns\n",
                "\n",
                "# Columns\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "list = ['RowId', 'YearStart', 'YearEnd', 'LocationAbbr', 'LocationDesc',\n",
                "       'Datasource', 'Class', 'Topic', 'Question', 'Data_Value_Unit',\n",
                "       'DataValueTypeID', 'Data_Value_Type', 'Data_Value', 'Data_Value_Alt',\n",
                "       'Data_Value_Footnote_Symbol', 'Data_Value_Footnote',\n",
                "       'Low_Confidence_Limit', 'High_Confidence_Limit',\n",
                "       'StratificationCategory1', 'Stratification1', 'StratificationCategory2',\n",
                "       'Stratification2', 'Geolocation', 'ClassID', 'TopicID', 'QuestionID',\n",
                "       'LocationID', 'StratificationCategoryID1', 'StratificationID1',\n",
                "       'StratificationCategoryID2', 'StratificationID2']\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "column_dict = {\n",
                "\t'question': \"Question\",\n",
                "\t\"location_abbrev\": \"LocationAbbr\",\n",
                "\t\"location_desc\": \"LocationDesc\",\n",
                "\t\"strat_cat_1\": \"StratificationCategory1\",\n",
                "\t\"strat_1_value\": \"Stratification1\",\n",
                "\t\"strat_cat_2\": \"StratificationCategory2\",\n",
                "\t\"strat_2_value\": \"Stratification2\",\n",
                "\t\"df_footnote\": \"Data_Value_Footnote\",\n",
                "\t\"id\": 'RowId',\n",
                "\t\"dv_type\": \"Data_Value_Type\"\n",
                "\t}"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "129ce836-524b-4ea8-b394-a959f9308d6a"
            },
            "source": [
                "## Get to Know the Numbers\n",
                "\n",
                "Now that you have everything setup, put any code that you use to get to know the dataframe and its rows and columns better in the cell below. You can use whatever techniques you like, except for visualizations. You will put those in a separate section.\n",
                "\n",
                "When working on your code, make sure to leave comments so that your mentors can understand your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "0ca2d318-f6e8-43ef-a33e-5304d24d928d",
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Is each row of my dataset an individual data point, or is it representing an aggregation (average, sum, etc.) of a dataset.\n",
                "\t## Each row represents an aggregation of survey responses for a given geographic region\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Unique locations\n",
                "## Are there regions mixed in with specific states in the data? -- YES\n",
                "\n",
                "unique_vals = df[column_dict['location_desc']].unique()\n",
                "unique_vals.sort()\n",
                "\n",
                "print(unique_vals)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Unique Age groups, Race/Ethnicity, Gender reported on for these two questions\n",
                "# filtered_df = df[df['City'] == 'New York']\n",
                "category = \"Age Group\"\n",
                "\n",
                "filtered_to_cat = df[df[column_dict['strat_cat_1']] == category]\n",
                "\n",
                "filtered_to_cat[column_dict['strat_1_value']].unique()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Unique Race/Ethnicity, \n",
                "\n",
                "category = 'Race/Ethnicity'\n",
                "\n",
                "filtered_to_cat = df[df[column_dict['strat_cat_2']] == category]\n",
                "\n",
                "filtered_to_cat[column_dict['strat_2_value']].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Unique Gender reported on for these two questions\n",
                "category = 'Gender'\n",
                "\n",
                "filtered_to_cat = df[df[column_dict['strat_cat_2']] == category]\n",
                "\n",
                "filtered_to_cat[column_dict['strat_2_value']].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Number of 'No Data Available' rows in the dataset for these questions\n",
                "\n",
                "row_val = \"No Data Available\"\n",
                "\n",
                "count_no_data = df[df[column_dict['df_footnote']] == row_val][column_dict['df_footnote']].count()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "6095\n",
                        "16287\n",
                        "37.42\n",
                        "10192\n"
                    ]
                }
            ],
            "source": [
                "## Number of rows with no data due to sample size warning\n",
                "row_val = \"Sample size of denominator and/or age group for age-standardization is less than 50 or relative standard error is more than 30%\"\n",
                "\n",
                "count_sample_warning = df[df[column_dict['df_footnote']] == row_val][column_dict['df_footnote']].count()\n",
                "\n",
                "\n",
                "total_no_data = count_no_data + count_sample_warning\n",
                "print(total_no_data)\n",
                "\n",
                "num_total_records = df[column_dict['id']].count()\n",
                "print(num_total_records)\n",
                "\n",
                "percent_missing = round((total_no_data / num_total_records) * 100, 2)\n",
                "print(percent_missing)\n",
                "\n",
                "# Total rows with data\n",
                "print(num_total_records - total_no_data)\n",
                "# when I move on to cleaning data, going to filter these no data rows out of dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array(['Percentage'], dtype=object)"
                        ]
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Value data types in dataset\n",
                "\n",
                "df[column_dict['dv_type']].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## <Important> Need to research what these High and Low confidence values mean\n",
                "\n",
                "# A low confidence limit (often referred to as the lower bound) is the lowest value in this range, \n",
                "##  while a high confidence limit (or upper bound) is the highest value. \n",
                "## Together, these limits form a confidence interval, \n",
                "## which provides an estimate of uncertainty around the parameter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "59\n",
                        "59\n"
                    ]
                }
            ],
            "source": [
                "## Unique Location values for rows with data and rows without data\n",
                "\n",
                "row_val_1 = \"No Data Available\"\n",
                "row_val_2 = \"Sample size of denominator and/or age group for age-standardization is less than 50 or relative standard error is more than 30%\"\n",
                "\n",
                "exclude = [row_val_1, row_val_2]\n",
                "\n",
                "\n",
                "filtered_df = df[~df[column_dict['df_footnote']].isin(exclude)]\n",
                "# Locations with data\n",
                "locations_with_data = filtered_df[column_dict['location_desc']].unique()\n",
                "\n",
                "no_data_df = df[df[column_dict['df_footnote']].isin(exclude)]\n",
                "locations_without_data = no_data_df[column_dict['location_desc']].unique()\n",
                "\n",
                "\n",
                "print(len(locations_with_data))\n",
                "print(len(locations_without_data))\n",
                "\n",
                "# All unique locations seem to have rows with data and rows without data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## See how filled out dataset is for both questions. Does one have more data than the other? That'd be an important thing to note in final \n",
                "### Tableau report if so. \n",
                "## What are the number of complete responses for each question? Can I compare them, or is one question much more answered than the other?\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "d45060f3-97bc-484a-9ef4-66145bbe9427"
            },
            "source": [
                "## Visualize\n",
                "\n",
                "Create any visualizations for your EDA here. Make note in the form of code comments of what your thought process is for your visualizations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "f4565b03-759a-47a8-b58f-01b32a0b4b67"
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "cd64bab1-db4c-4295-820d-c6464b653a3e"
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "d4931c0c-2c09-4ee1-95d4-73dd08c2f0a6"
            },
            "source": [
                "## Summarize Your Results\n",
                "\n",
                "With your EDA complete, answer the following questions.\n",
                "\n",
                "1. Was there anything surprising about your dataset? \n",
                "2. Do you have any concerns about your dataset? \n",
                "3. Is there anything you want to make note of for the next phase of your analysis, which is cleaning data? "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
